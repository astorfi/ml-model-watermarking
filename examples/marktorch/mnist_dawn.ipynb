{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce144b5-0e21-480c-afb7-832af4b24880",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DAWN: Dynamic Adversarial Watermarking of Neural Networks\n",
    "\n",
    "Implementation of the work presented in the paper [DAWN: Dynamic Adversarial Watermarking of Neural Networks](https://arxiv.org/pdf/1906.00830.pdf).\n",
    "\n",
    "## Paper Abstract\n",
    "Training machine learning (ML) models is expensive in terms of\n",
    "computational power, amounts of labeled data and human expertise.\n",
    "Thus, ML models constitute intellectual property (IP) and business\n",
    "value for their owners. Embedding digital watermarks during model\n",
    "training allows a model owner to later identify their models in\n",
    "case of theft or misuse. However, model functionality can also be\n",
    "stolen via model extraction, where an adversary trains a surrogate\n",
    "model using results returned from a prediction API of the original\n",
    "model. Recent work has shown that model extraction is a realistic\n",
    "threat. Existing watermarking schemes are ineffective against IP\n",
    "theft via model extraction since it is the adversary who trains the\n",
    "surrogate model. In this paper, we introduce DAWN (Dynamic\n",
    "Adversarial Watermarking of Neural Networks), the first approach\n",
    "to use watermarking to deter model extraction IP theft. Unlike prior\n",
    "watermarking schemes, DAWN does not impose changes to the\n",
    "training process but it operates at the prediction API of the protected\n",
    "model, by dynamically changing the responses for a small subset of\n",
    "queries (e.g., <0.5%) from API clients. This set is a watermark that\n",
    "will be embedded in case a client uses its queries to train a surrogate\n",
    "model. We show that DAWN is resilient against two state-of-the-art\n",
    "model extraction attacks, effectively watermarking all extracted\n",
    "surrogate models, allowing model owners to reliably demonstrate\n",
    "ownership, incurring negligible loss of\n",
    "prediction accuracy (0.03\\%-0.5\\%).\n",
    "\n",
    "## Goals\n",
    "\n",
    "The authers in the paper follow two different roles:\n",
    "\n",
    "1. Provide a robust framework againts model extraction attacks.\n",
    "2. Utilizing watermarking to maintain the model ownership via a robust approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796c314-3745-489a-bd41-ead132b1ebb0",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee835b1-5aff-49ca-849a-0667a95156c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "from warnings import simplefilter\n",
    "\n",
    "from mlmodelwatermarking.marktorch import Trainer\n",
    "from mlmodelwatermarking.verification import verify\n",
    "from mlmodelwatermarking import TrainingWMArgs\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e7883-302f-470c-8553-196c6b6f9e17",
   "metadata": {},
   "source": [
    "## Model architecture and DB construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390acf49-1202-483d-afc9-af9b724571c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \"\"\" MNIST model \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def load_MNIST():\n",
    "    \"\"\" Load MNIST dataset\n",
    "    Returns:\n",
    "    trainloader (object): training dataloader\n",
    "    testloader (object): test dataloader\n",
    "\n",
    "    \"\"\"\n",
    "    transformation = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "    ])\n",
    "    dataset = torchvision.datasets.MNIST('/tmp/',\n",
    "                                         train=True,\n",
    "                                         download=True,\n",
    "                                         transform=transformation)\n",
    "    size_split = int(len(dataset) * 0.8)\n",
    "    trainset, valset = torch.utils.data.random_split(\n",
    "        dataset, [size_split, len(dataset) - size_split])\n",
    "\n",
    "    testset = torchvision.datasets.MNIST('/tmp/',\n",
    "                                         train=False,\n",
    "                                         download=True,\n",
    "                                         transform=transformation)\n",
    "\n",
    "    return trainset, valset, testset\n",
    "\n",
    "simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6409087-8725-4062-95a2-236d9323fa8f",
   "metadata": {},
   "source": [
    "## Main Watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b642cb-03b5-4bfa-9eff-9b102e9f03b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Training\n",
      "Validation accuracy: 98.3167: 100%|█████████████| 10/10 [02:26<00:00, 14.67s/it]\n",
      "INFO:logger:Generation of the trigers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is stolen: True\n",
      "Model is stolen: False\n"
     ]
    }
   ],
   "source": [
    "def default_key(length: int):\n",
    "    elements = string.ascii_uppercase + string.digits\n",
    "    return ''.join(random.choices(elements, k=length))\n",
    "\n",
    "\n",
    "\"\"\"Testing of watermarking for MNIST model.\"\"\"\n",
    "\n",
    "# WATERMARKED\n",
    "model = LeNet()\n",
    "\n",
    "trainset, valset, testset = load_MNIST()\n",
    "model = LeNet()\n",
    "args = TrainingWMArgs(\n",
    "        trigger_technique='merrer',\n",
    "        optimizer='SGD',\n",
    "        lr=0.01,\n",
    "        gpu=True,\n",
    "        epochs=10,\n",
    "        nbr_classes=10,\n",
    "        batch_size=64,\n",
    "        watermark=False)\n",
    "\n",
    "trainer_clean = Trainer(\n",
    "                model=model,\n",
    "                args=args,\n",
    "                trainset=trainset,\n",
    "                valset=valset,\n",
    "                testset=testset)\n",
    "trainer_clean.train()\n",
    "original_model = trainer_clean.get_model()\n",
    "\n",
    "args = TrainingWMArgs(\n",
    "            nbr_classes=10,\n",
    "            key_dawn=default_key(255),\n",
    "            probability_dawn=0.01,\n",
    "            trigger_technique='dawn',\n",
    "            metric='accuracy')\n",
    "\n",
    "trainer = Trainer(\n",
    "            model=original_model,\n",
    "            trainset=trainset,\n",
    "            args=args)\n",
    "\n",
    "ownership, wm_model = trainer.get_model()\n",
    "triggerloader = torch.utils.data.DataLoader(\n",
    "                    ownership['inputs'],\n",
    "                    batch_size=32,\n",
    "                    shuffle=True)\n",
    "results = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for _, data in enumerate(triggerloader):\n",
    "    inputs = data\n",
    "    pred = wm_model(inputs.to(device))\n",
    "    results += list(torch.argmax(pred, 1).cpu().numpy())\n",
    "\n",
    "verification = verify(\n",
    "                ownership['labels'],\n",
    "                results,\n",
    "                number_labels=args.nbr_classes,\n",
    "                metric='accuracy',\n",
    "                dawn=True)\n",
    "\n",
    "# This should return True\n",
    "print(f\"Model is stolen: {verification['is_stolen']}\")\n",
    "\n",
    "results = []\n",
    "for _, data in enumerate(triggerloader):\n",
    "    inputs = data\n",
    "    pred = original_model(inputs.to(device))\n",
    "    results += list(torch.argmax(pred, 1).cpu().numpy())\n",
    "\n",
    "verification = verify(\n",
    "                ownership['labels'],\n",
    "                results,\n",
    "                number_labels=args.nbr_classes,\n",
    "                metric='accuracy')\n",
    "\n",
    "# This should return False\n",
    "print(f\"Model is stolen: {verification['is_stolen']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3485309d-c6d4-476a-93fb-fb8eb5007476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlenv] *",
   "language": "python",
   "name": "conda-env-dlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
